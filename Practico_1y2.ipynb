{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:ausentismo] *",
      "language": "python",
      "name": "conda-env-ausentismo-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Practico_AyV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benotti/diplodatos2020/blob/master/Practico_1y2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Caa69yAuq6l",
        "colab_type": "text"
      },
      "source": [
        "# **Análisis, Visualización y Curación de Datos**\n",
        "\n",
        "## **Enunciado**\n",
        "\n",
        "#### **Descripción del dataset**\n",
        "\n",
        "El dataset que usaremos en este proyecto consiste de diálogos escritos y sincrónicos entre un docente y un estudiante a través de un app de mensajería instantánea similar a Whatsapp. El dataset fue recolectado por la empresa que contrata a los docentes y los pone en contacto con estudiantes a través de una app que desarrollaron para ese fin. Los docentes son tutores particulares, los estudiantes pueden conectarse en cualquier momento y pedir entrar en contacto con algún tutor a través de la app. Los diálogos son conversaciones cuyo objetivo es ayudar a los estudiantes a resolver las tareas de matemática, química y física de la escuela secundaria. El dataset completo tiene 18K diálogos que suman 7K horas pero no lo usaremos completo para este proyecto. Como los diálogos se basan en didáctica \"inquiry-based\" los docentes hacen muchas preguntas. Hay 240K preguntas en el dataset. Al finalizar el diálogo los estudiantes evalúan cuán satisfechos están con la clase particular con una nota de 1 a 5. Es un dataset grande, con timestamps en cada turno, con información demográfica de los participantes: género, edad, notas en exámenes, tipo de pago del servicio, país, etc. Los estudiantes son mayormente de Estados Unidos por lo que los diálogos están en inglés, los docentes son de todo el mundo y trabajan 100% remotos.\n",
        "\n",
        "#### **Primeros pasos**\n",
        "\n",
        "* Caracterizar a los tutores en términos de edad, sexo y país. Para el caso de la edad, determinar si los datos siguen alguna alguna distribución conocida. Para el sexo, determinar si hay una diferencia significativa entre hombres y mujeres. Graficar.\n",
        "\n",
        "* Determinar la cantidad de diálogos del dataset, cantidad de tutores, y cantidad de estudiantes. Determinar cuántos turnos hay del tutor y cuántos del estudiante en total y en promedio por diálogo. Graficar la distribución. \n",
        "\n",
        "* Elegir (al menos) tres variables, las cuales crean que pueden estar correlacionadas con la satisfacción del estudiante al terminar el diálogo. Para cada una de ellas calcular la probabilidad de que el estudiante dé una evaluación negativa (1 o 2), condicionada a esa variable. \n",
        "\n",
        "\n",
        "#### **Sugerencias**\n",
        "\n",
        "* Transformar cada campo de acuerdo con su tipo de variable (entero, fecha, string, etc).\n",
        "\n",
        "* Visualizar la distribución de datos de cada campo utilizando gráficos que consideren adecuados según lo aprendido en la materia. Además de lo solicitado aquí. \n",
        "\n",
        "\n",
        "#### **Desde las Ciencias de la Educación**\n",
        "\n",
        "Cuando uno piensa en el éxito de un diálogo educativo lo primero que consideramos es el desempeño del docente. Sin embargo, por teorías de las ciencias de la educación sabemos que la actitud y predisposición del estudiante juega un rol crucial. ¿Podemos ver en este dataset cómo la participacipación de los estudiantes influencia la nota que los estudiantes asignan a la clase?\n",
        "\n",
        "* Analizar la cantidad de palabras promedio de los turnos de los estudiantes dentro de un diálogo en general, para los diálogos evaluados como positivos (4, 5), y para los diálogos evaluados como negativos (1, 2). ¿La diferencia es significativa entre diálogos positivos y negativos? Correlacionar esta variable con la \"nota\" que el estudiante pone al tutor en ese diálogo. \n",
        "\n",
        "* Analizar la cantidad de turnos del estudiante y el largo de los diálogos. Correlacionar esta variable con la \"nota\" del diálogo. Calcular el promedio de cantidad de turnos para los diálogos positivos y negativos. ¿La diferencia es significativa?\n",
        "\n",
        "\n",
        "#### **Desde el procesamiento de lenguaje natural**\n",
        "\n",
        "Como verán el dataset ya se encuentra tokenizado, es decir separado en palabras. La separación se realizó usando https://spacy.io/api/tokenizer/. La tokenización puede parecer un proceso sencillo porque es separar las strings en los espacios, pero no siempre lo es. Sobre todo cuando el texto es ruidoso como en nuestro dataset, pueden faltar espacios en blanco o incluir de más. Tokenizar emoticones y otros símbolos tampoco es sencillo. Spacy puede cometer errores pero es lo suficientemente bueno para nuestros objetivos. Para más información ver [1]. En PLN llamamos ngramas a las secuencias de n tokens o palabras. Un unigrama es una secuencia se 1 token, por lo tanto es una única palabra. Para más información [2].\n",
        "\n",
        "* Calcular el tamaño del vocabulario del tutor y del estudiante por separado. Calcular los mismos valores pero eliminando las palabras que se repiten 3 o menos veces.\n",
        "\n",
        "* Realizar un gráfico frecuencia de unigramas del tutor. ¿Se cumple la ley de Zipf? Visualizar los 20 unigramas más frecuentes, los 20 unigramas menos frecuentes y 20 unigramas aleatorios en el medio de la distribución. Tratar de caracterizar las palabras, sacar conclusiones sobre qué tipo de palabras son, si son valiosas o no y cómo podríamos explotarlas o eliminar el ruido que traen. Hacer lo mismo para 2-gramas y 3 gramas.\n",
        "\n",
        "* Realizar el mismo análisis, pero sobre los turnos del estudiante. Opcional: Repetir el análisis quitando las palabras con una frecuencia menor o igual que 3. \n",
        "\n",
        "* ¿Observan diferencias entre el estudiante y el tutor? ¿Les parece que los n-gramas más frecuentes y menos frecuentes serán útiles para predecir la satisfacción del estudiante?\n",
        "\n",
        "* Intenten encontrar correlaciones entre palabras que ocurren una seguida de la otra, es decir, traten de identificar qué palabras ocurren más frecuentemente de lo que podríamos considerar casualidad detrás de otra palabra. A esta medida se la llama Información Mutua y su instanciación en el Procesamiento del Lenguaje Natural se llama Información Mutua Puntual (IMP) [3]. Encuentren cómo se implementa, y encuentren las secuencias de palabras con mayor IMP. ¿Qué observan? ¿Nos van a resultar útiles para nuestro objetivo de predecir la satisfacción del estudiante?\n",
        "\n",
        "Existe librerías para detectar términos multipalabra y en particular, entidades nombradas (como Costa Rica) [4] que se pueden usar en lugar de n-gramas. Sin embargo, estas librerías están entrenadas para discurso (noticias, y wikipedia) y para entidades como personas, fechas, lugares y, en mi experiencia, no andan bien para diálogos educativos sobre matemáticas o química (quizás funcionarían mejor para diálogos sobre historia o geografía). \n",
        "\n",
        "\n",
        "## **Entrega**\n",
        "\n",
        "**Formato de entrega:** Deberán entregar el análisis realizado, junto con los códigos con los que hicieron el análisis. Pueden optar por un único Notebook que alterne celdas de código con una descripción detallada, o bien, un Notebook más centrado en los códigos, junto con una presentación que detalle el análisis.\n",
        "\n",
        "**Fecha de entrega:** 19/7\n",
        "\n",
        "## **Referencias:**\n",
        "\n",
        "* [1] https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html y https://www.fing.edu.uy/inco/cursos/intropln/pres/2011%2005%20-%20Preprocesamiento%20y%20tokenizaci%C3%B3n.pdf\n",
        "* [2] https://es.wikipedia.org/wiki/N-grama\n",
        "* [3] https://es.wikipedia.org/wiki/Punto_de_informaci%C3%B3n_mutua\n",
        "* [4] https://es.wikipedia.org/wiki/Reconocimiento_de_entidades_nombradas\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TTshRFbuq6n",
        "colab_type": "text"
      },
      "source": [
        "## Código inicial\n",
        "\n",
        "En esta parte falta actualizar la dirección del dataset. El dataset está partido en 2 archivos que tienen un ID en común. Para varios de estos ejercicios no es necesario hacer join. Cuando se definan los estudiantes de este proyecto se compartirá el dataset con ellos de forma privada luego de que se comprometan a lo siguiente: El dataset *no* es público y *no* puede publicarse públicamente en internet. \n",
        "\n",
        "Importamos librerías y configuración general"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le95l18luq6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.display.max_columns = 30\n",
        "pd.options.display.max_rows = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcL0tTpsuq6y",
        "colab_type": "text"
      },
      "source": [
        "Leemos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm5UX6upuq6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = os.path.join('..', 'data')\n",
        "data_file_name = 'dataset_name.csv'\n",
        "full_data_file_name = os.path.join(data_dir, data_file_name)\n",
        "df = pd.read_csv(full_data_file_name, sep=';')\n",
        "print(df.shape)\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg6P0H0Juq67",
        "colab_type": "text"
      },
      "source": [
        "Analizamos los tipos de datos de cada campo inferidos por `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nBOdR7Uuq69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtypes = pd.DataFrame(df.dtypes)\n",
        "dtypes.index.name = 'Campo'\n",
        "dtypes.rename(columns={0: 'Tipo'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siqQ9c6huq7D",
        "colab_type": "text"
      },
      "source": [
        "Transformamos el timestamp en *datetime*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRb9WZXguq7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.REEMPLAZAR = pd.to_datetime(df.REEMPLAZAR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtYPt2v4uq7I",
        "colab_type": "text"
      },
      "source": [
        "Buscamos posibles duplicados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBTeukrKuq7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPHZVFINuq7Q",
        "colab_type": "text"
      },
      "source": [
        "Verificamos que los turnos estén ordenados por fecha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeKNeJIxuq7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Este valor debería ser no negativo\n",
        "df.sort_values(by='FechaDelTurno').FechaDelTurno.diff().min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFA-72ciuq7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
